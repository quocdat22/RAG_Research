# API Configuration (Either OpenAI or GitHub)
OPENAI_API_KEY=
GITHUB_TOKEN=
COHERE_API_KEY=
LLAMA_CLOUD_API_KEY=
API_BASE_URL=https://models.github.ai/inference

# Supabase Configuration (Auto-enabled when ENVIRONMENT=production)
SUPABASE_URL=
SUPABASE_KEY=
USE_SUPABASE_STORAGE=TRUE  # Set true to force Supabase in development

# LlamaParse Settings (for complex PDF parsing)
LLAMAPARSE_ENABLED=true
LLAMAPARSE_OUTPUT_TABLES_AS_HTML=false

# Embedding Settings
EMBEDDING_MODEL=openai/text-embedding-3-small
EMBEDDING_DIMENSION=1536

# LLM Settings
LLM_MODEL=openai/gpt-4o-mini
LLM_MODEL_LIGHT=openai/gpt-4.1-mini
LLM_MODEL_HEAVY=openai/gpt-4o
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048

# Chunking Settings
CHUNK_SIZE=800
CHUNK_OVERLAP=200

# Retrieval Settings
TOP_K=3
VECTOR_WEIGHT=0.7
BM25_WEIGHT=0.3

# Rerank Settings
RERANK_ENABLED=true
RERANK_MODEL=rerank-v4.0-fast
RERANK_TOP_N=3
RERANK_INITIAL_TOP_K=5

# Storage Paths
DOCUMENTS_DIR=./data/documents
CHROMA_DIR=./data/chroma_db
LOG_DIR=./logs

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
ALLOWED_ORIGINS=*
ENVIRONMENT=development

BACKEND_API_URL = "https://your-backend.onrender.com"
